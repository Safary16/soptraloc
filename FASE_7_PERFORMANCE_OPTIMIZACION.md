# ‚ö° AUDITOR√çA - FASE 7: PERFORMANCE Y OPTIMIZACI√ìN

**Fecha**: 2025-10-10  
**Auditor**: GitHub Copilot  
**Alcance**: An√°lisis exhaustivo de performance: queries N+1, select_related/prefetch_related, caching, indexing, database connection pooling, Celery optimization, profiling

---

## üìä RESUMEN EJECUTIVO

### Estad√≠sticas de Performance
- **Queries N+1 identificados**: 5+ casos cr√≠ticos
- **select_related usage**: üü° 20+ casos implementados (correcto)
- **prefetch_related usage**: üî¥ Solo 1 caso (falta optimizaci√≥n many-to-many)
- **Caching**: üî¥ Redis configurado pero **casi sin uso** (solo Mapbox con 5min TTL)
- **√çndices DB**: üü¢ 6 √≠ndices en Container, algunos en otras tablas
- **Celery tasks**: üü¢ 7 tasks as√≠ncronos correctos
- **Database pooling**: üü° Sin configuraci√≥n expl√≠cita (usando default)
- **Compresi√≥n**: ‚ùå No configurada (WhiteNoise sin GZip)

### Veredicto General de Performance
üü° **MODERADO/BUENO** - Sistema usa `select_related` correctamente en ViewSets principales, tiene √≠ndices b√°sicos y Celery configurado. **PERO falta cache estrat√©gico (stats, dashboard), prefetch_related para relaciones m√∫ltiples, √≠ndices compuestos adicionales, y compresi√≥n de assets**.

---

## 1Ô∏è‚É£ AN√ÅLISIS DE QUERIES N+1

### üü¢ **FORTALEZA: select_related en ViewSets principales**

```python
# ‚úÖ apps/containers/views.py (l√≠nea 45)
class ContainerViewSet(viewsets.ModelViewSet):
    queryset = Container.objects.filter(is_active=True).select_related(
        'owner_company', 'current_location', 'current_vehicle'
    )
```

**Fortalezas**:
- ‚úÖ ViewSet principal optimizado con `select_related`
- ‚úÖ Evita N+1 en ForeignKeys m√°s usados

---

### üî¥ **PROBLEMA CR√çTICO: N+1 en dashboard_view**

```python
# ‚ùå apps/core/auth_views.py (l√≠neas 119-126)
@login_required
def dashboard_view(request):
    """Dashboard principal con contenedores programados"""
    
    base_queryset = Container.objects.select_related(
        'conductor_asignado',
        'client',
        'terminal',
        'owner_company',
        'vessel',
        'agency',
        'shipping_line'
    )
    # ‚úÖ select_related BIEN usado aqu√≠
    
    # Pero luego...
    
    # ‚ùå PROBLEMA: Multiple .count() queries sin cache
    stats = {
        'por_arribar': normalized_counts.get('POR_ARRIBAR', 0),
        'programados': normalized_counts.get('PROGRAMADO', 0),
        'en_proceso': normalized_counts.get('EN_PROCESO', 0),
        # ... 13 counts diferentes
    }
    # ‚Üê 1 query para obtener counts (correcto con .values().annotate())
    
    # ‚ùå PROBLEMA: Queries separados para alertas
    'alertas_activas': Alert.objects.filter(is_active=True).count(),
    # ‚Üê +1 query
    
    # ‚ùå PROBLEMA: En template, si iteramos por contenedores y accedemos a:
    # {{ container.conductor_asignado.nombre }}  ‚Üê Ya optimizado con select_related
    # {{ container.client.name }}                ‚Üê Ya optimizado
    # 
    # PERO si accedemos a relaciones many-to-many o reverse FK sin prefetch:
    # {{ container.movimientos.count }}          ‚Üê N+1 query!
    # {{ container.documentos.count }}           ‚Üê N+1 query!
```

**An√°lisis del problema**:
En el dashboard actual, el N+1 est√° parcialmente resuelto con `select_related` para ForeignKeys. **PERO**:

1. **Falta cache** para stats (se recalculan en cada request)
2. **Falta prefetch_related** si se accede a relaciones inversas (movimientos, documentos, inspecciones)

---

### üî¥ **PROBLEMA: N+1 en resueltos_view con multiple counts**

```python
# ‚ö†Ô∏è apps/core/auth_views.py (l√≠neas 247-250)
stats = {
    'asignados': contenedores_resueltos.filter(status='ASIGNADO').count(),
    'en_ruta': contenedores_resueltos.filter(status='EN_RUTA').count(),
    'arribados': contenedores_resueltos.filter(status='ARRIBADO').count(),
    'finalizados': contenedores_resueltos.filter(status='FINALIZADO').count(),
}
# ‚Üê 4 queries separados para contar
```

**Soluci√≥n**:
```python
# ‚úÖ CORREGIR: 1 query con annotate

from django.db.models import Count, Q

# Opci√≥n 1: Usando conditional aggregation
stats = contenedores_resueltos.aggregate(
    asignados=Count('id', filter=Q(status='ASIGNADO')),
    en_ruta=Count('id', filter=Q(status='EN_RUTA')),
    arribados=Count('id', filter=Q(status='ARRIBADO')),
    finalizados=Count('id', filter=Q(status='FINALIZADO')),
)
# ‚Üê 1 solo query!

# Opci√≥n 2: Si necesitas todos los counts
status_counts = contenedores_resueltos.values('status').annotate(count=Count('id'))
stats = {item['status']: item['count'] for item in status_counts}
stats_normalized = {
    'asignados': stats.get('ASIGNADO', 0),
    'en_ruta': stats.get('EN_RUTA', 0),
    'arribados': stats.get('ARRIBADO', 0),
    'finalizados': stats.get('FINALIZADO', 0),
}
# ‚Üê Tambi√©n 1 solo query
```

---

### üü° **MEJORA: Agregar prefetch_related para relaciones many-to-many**

```python
# ‚ö†Ô∏è Si en alg√∫n lugar accedes a relaciones inversas sin prefetch:

# ‚ùå MAL:
containers = Container.objects.select_related('owner_company').all()
for container in containers:
    print(container.movimientos.count())  # ‚Üê N+1 query!
    print(container.documentos.count())   # ‚Üê N+1 query!

# ‚úÖ BIEN:
containers = Container.objects.select_related('owner_company').prefetch_related(
    'movimientos',
    'documentos',
    'inspecciones'
).all()
for container in containers:
    print(container.movimientos.count())  # ‚Üê 0 queries adicionales
    print(container.documentos.count())   # ‚Üê 0 queries adicionales
```

**Soluci√≥n**:
```python
# ‚úÖ AGREGAR: En ViewSets que necesiten relaciones inversas

class ContainerViewSet(viewsets.ModelViewSet):
    def get_queryset(self):
        qs = Container.objects.filter(is_active=True).select_related(
            'owner_company', 'current_location', 'current_vehicle',
            'conductor_asignado', 'client', 'terminal', 'vessel', 'agency', 'shipping_line'
        )
        
        # ‚úÖ Si action es 'retrieve' (detalle), prefetch relaciones
        if self.action == 'retrieve':
            qs = qs.prefetch_related(
                'movimientos',
                'documentos',
                'inspecciones',
                # Puedes hacer prefetch anidado:
                Prefetch(
                    'movimientos',
                    queryset=ContainerMovement.objects.select_related('from_location', 'to_location', 'to_vehicle')
                )
            )
        
        return qs
```

---

## 2Ô∏è‚É£ AN√ÅLISIS DE CACHING

### üî¥ **PROBLEMA CR√çTICO: Redis configurado pero casi sin uso**

```python
# ‚úÖ config/settings.py (l√≠nea 197)
CELERY_BROKER_URL = config('REDIS_URL', default='redis://localhost:6379')
CELERY_RESULT_BACKEND = config('REDIS_URL', default='redis://localhost:6379')

# ‚Üê Redis est√° configurado para Celery, pero NO para cache general de Django
```

**Estado actual**:
- ‚úÖ Redis corriendo para Celery (broker + result backend)
- üî¥ Django NO usa Redis para cache (sin configuraci√≥n de CACHES)
- üü° Solo 1 uso de cache: Mapbox API con TTL de 5 minutos

```python
# ‚ö†Ô∏è apps/routing/mapbox_service.py (l√≠neas 106, 227)
cache_key = f"mapbox_travel:{origin_query}:{dest_query}"
cached = cache.get(cache_key)
if cached and not departure_time:
    return cached
# ...
cache.set(cache_key, result, 300)  # ‚Üê 5 minutos
```

**Problemas**:
- üî¥ Stats del dashboard se recalculan en **cada request** (sin cache)
- üî¥ Counts de contenedores por status se recalculan (sin cache)
- üî¥ Queries frecuentes no se cachean (listados, b√∫squedas)
- üî¥ TimeMatrix podr√≠a cachearse (no cambia seguido)

---

### ‚úÖ **SOLUCI√ìN: Implementar cache estrat√©gico con Redis**

```python
# ‚úÖ PASO 1: Configurar Redis como backend de cache

# config/settings.py
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.redis.RedisCache',
        'LOCATION': config('REDIS_URL', default='redis://localhost:6379/1'),  # ‚Üê DB 1 para cache
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
        },
        'KEY_PREFIX': 'soptraloc',
        'TIMEOUT': 300,  # 5 minutos por defecto
    }
}

# Si quieres cache de templates:
TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'OPTIONS': {
            ...
            'loaders': [
                ('django.template.loaders.cached.Loader', [
                    'django.template.loaders.filesystem.Loader',
                    'django.template.loaders.app_directories.Loader',
                ]),
            ] if not DEBUG else [
                'django.template.loaders.filesystem.Loader',
                'django.template.loaders.app_directories.Loader',
            ],
        },
    },
]

# ‚úÖ PASO 2: Cachear stats del dashboard

# apps/core/auth_views.py
from django.core.cache import cache
from django.views.decorators.cache import cache_page

@login_required
@cache_page(60 * 2)  # ‚Üê Cache 2 minutos
def dashboard_view(request):
    """Dashboard con cache de 2 minutos"""
    ...

# O cache manual m√°s granular:
@login_required
def dashboard_view(request):
    """Dashboard con cache selectivo"""
    
    # Cache de stats (5 minutos)
    cache_key = 'dashboard:stats'
    stats = cache.get(cache_key)
    
    if stats is None:
        raw_status_counts = Container.objects.values_list('status').annotate(count=Count('id'))
        normalized_counts = {
            summary.code: summary.count for summary in summarize_statuses(raw_status_counts)
        }
        
        stats = {
            'total': sum(normalized_counts.values()),
            'por_arribar': normalized_counts.get('POR_ARRIBAR', 0),
            'programados': normalized_counts.get('PROGRAMADO', 0),
            # ... todos los stats
        }
        
        cache.set(cache_key, stats, 300)  # ‚Üê 5 minutos
    
    # Containers NO se cachean (cambian frecuentemente)
    containers = base_queryset.filter(...)
    
    return render(request, 'dashboard.html', {
        'stats': stats,
        'containers': containers,
    })

# ‚úÖ PASO 3: Invalidar cache cuando cambian datos

# apps/containers/views.py
class ContainerViewSet(viewsets.ModelViewSet):
    def perform_create(self, serializer):
        serializer.save()
        # Invalidar cache de stats
        cache.delete('dashboard:stats')
    
    def perform_update(self, serializer):
        serializer.save()
        # Invalidar cache si cambi√≥ status
        if 'status' in serializer.validated_data:
            cache.delete('dashboard:stats')

# ‚úÖ PASO 4: Cache para queries costosos

# apps/containers/services/stats_service.py
from django.core.cache import cache

class ContainerStatsService:
    """Servicio de estad√≠sticas con cache"""
    
    @staticmethod
    def get_status_counts(force_refresh=False):
        """Obtiene counts por status con cache de 5 minutos"""
        cache_key = 'container:status_counts'
        
        if not force_refresh:
            cached = cache.get(cache_key)
            if cached:
                return cached
        
        counts = Container.objects.values('status').annotate(count=Count('id'))
        result = {item['status']: item['count'] for item in counts}
        
        cache.set(cache_key, result, 300)
        return result
    
    @staticmethod
    def get_driver_availability():
        """Cache de disponibilidad de conductores"""
        cache_key = 'drivers:availability'
        
        cached = cache.get(cache_key)
        if cached:
            return cached
        
        result = Driver.objects.filter(is_active=True).values('status').annotate(count=Count('id'))
        availability = {item['status']: item['count'] for item in result}
        
        cache.set(cache_key, availability, 180)  # 3 minutos
        return availability

# ‚úÖ PASO 5: Cache de API responses (DRF)

# Instalar: pip install drf-extensions

# apps/containers/views.py
from rest_framework_extensions.cache.decorators import cache_response
from rest_framework_extensions.cache.mixins import CacheResponseMixin

class ContainerViewSet(CacheResponseMixin, viewsets.ModelViewSet):
    """‚úÖ Con cache de respuestas API"""
    
    # Cache de 5 minutos para list y retrieve
    @cache_response(timeout=300, key_func='calculate_cache_key')
    def list(self, request, *args, **kwargs):
        return super().list(request, *args, **kwargs)
    
    def calculate_cache_key(self, view_instance, view_method, request, args, kwargs):
        """Genera cache key √∫nico por usuario y filtros"""
        user_id = request.user.id if request.user.is_authenticated else 'anon'
        query_params = request.query_params.urlencode()
        return f'container:list:{user_id}:{query_params}'
```

---

## 3Ô∏è‚É£ AN√ÅLISIS DE INDEXING

### üü¢ **FORTALEZA: √çndices b√°sicos implementados**

```python
# ‚úÖ apps/containers/models.py (l√≠neas 335-342)
class Container(models.Model):
    ...
    class Meta:
        indexes = [
            models.Index(fields=['status'], name='idx_status'),
            models.Index(fields=['scheduled_date'], name='idx_scheduled'),
            models.Index(fields=['conductor_asignado'], name='idx_driver'),
            models.Index(fields=['container_number'], name='idx_number'),
            models.Index(fields=['status', 'scheduled_date'], name='idx_status_date'),
            models.Index(fields=['conductor_asignado', 'status'], name='idx_driver_status'),
        ]
```

**Fortalezas**:
- ‚úÖ √çndices en campos m√°s consultados: `status`, `scheduled_date`, `conductor_asignado`, `container_number`
- ‚úÖ √çndices compuestos: `(status, scheduled_date)`, `(conductor_asignado, status)`

---

### üü° **MEJORA: Faltan √≠ndices adicionales**

```python
# ‚ö†Ô∏è FALTAN √≠ndices para:
# - owner_company (frecuentemente filtrado)
# - is_active (usado en queryset principal)
# - created_at, updated_at (para sorting temporal)
# - Campos de b√∫squeda: seal_number, customs_document
```

**Soluci√≥n**:
```python
# ‚úÖ AGREGAR: √çndices adicionales

# apps/containers/models.py
class Container(models.Model):
    ...
    class Meta:
        indexes = [
            # √çndices existentes
            models.Index(fields=['status'], name='idx_status'),
            models.Index(fields=['scheduled_date'], name='idx_scheduled'),
            models.Index(fields=['conductor_asignado'], name='idx_driver'),
            models.Index(fields=['container_number'], name='idx_number'),
            models.Index(fields=['status', 'scheduled_date'], name='idx_status_date'),
            models.Index(fields=['conductor_asignado', 'status'], name='idx_driver_status'),
            
            # ‚úÖ NUEVOS √≠ndices
            models.Index(fields=['owner_company'], name='idx_owner'),
            models.Index(fields=['is_active', 'status'], name='idx_active_status'),
            models.Index(fields=['created_at'], name='idx_created'),
            models.Index(fields=['updated_at'], name='idx_updated'),
            models.Index(fields=['seal_number'], name='idx_seal'),
            
            # √çndice para dashboard (filtro com√∫n)
            models.Index(
                fields=['is_active', 'status', 'scheduled_date'], 
                name='idx_dashboard_filter'
            ),
            
            # √çndice para b√∫squeda de contenedores sin asignar
            models.Index(
                fields=['status', 'conductor_asignado'], 
                name='idx_unassigned',
                condition=Q(conductor_asignado__isnull=True)  # ‚Üê Partial index
            ),
        ]

# ‚úÖ Generar migraci√≥n:
# python manage.py makemigrations
# python manage.py migrate

# ‚úÖ AGREGAR: √çndices en otros modelos

# apps/drivers/models.py
class Driver(models.Model):
    ...
    class Meta:
        indexes = [
            models.Index(fields=['status'], name='idx_driver_status'),
            models.Index(fields=['is_active', 'status'], name='idx_driver_active'),
            models.Index(fields=['rut'], name='idx_driver_rut'),  # ‚Üê B√∫squedas frecuentes
            models.Index(fields=['company'], name='idx_driver_company'),
        ]

# apps/routing/models.py
class Assignment(models.Model):
    ...
    class Meta:
        indexes = [
            models.Index(fields=['container'], name='idx_assignment_container'),
            models.Index(fields=['driver'], name='idx_assignment_driver'),
            models.Index(fields=['status', 'scheduled_date'], name='idx_assignment_scheduled'),
            models.Index(fields=['created_at'], name='idx_assignment_created'),
        ]

class TimeMatrix(models.Model):
    ...
    class Meta:
        indexes = [
            # √çndice compuesto para lookups origen-destino
            models.Index(fields=['origen', 'destino'], name='idx_timematrix_route'),
            models.Index(fields=['updated_at'], name='idx_timematrix_updated'),
        ]
```

---

## 4Ô∏è‚É£ AN√ÅLISIS DE CELERY Y TAREAS AS√çNCRONAS

### üü¢ **FORTALEZA: Celery bien configurado**

```python
# ‚úÖ config/settings.py (l√≠neas 197-202)
CELERY_BROKER_URL = config('REDIS_URL', default='redis://localhost:6379')
CELERY_RESULT_BACKEND = config('REDIS_URL', default='redis://localhost:6379')
CELERY_ACCEPT_CONTENT = ['application/json']  # ‚Üê JSON (seguro)
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = TIME_ZONE
```

**Fortalezas**:
- ‚úÖ Redis como broker (r√°pido y confiable)
- ‚úÖ JSON serializer (seguro, no pickle)
- ‚úÖ Result backend configurado

---

### üü¢ **FORTALEZA: 7 tasks as√≠ncronos implementados**

```python
# ‚úÖ apps/containers/tasks.py

@shared_task
def check_containers_requiring_assignment():
    """Verifica contenedores que necesitan asignaci√≥n"""
    ...

@shared_task
def check_late_assignments():
    """Verifica asignaciones atrasadas"""
    ...

@shared_task
def check_critical_assignments():
    """Verifica asignaciones cr√≠ticas"""
    ...

@shared_task
def check_containers_pending_return():
    """Verifica contenedores pendientes de devoluci√≥n"""
    ...

@shared_task
def calculate_daily_metrics():
    """Calcula m√©tricas diarias"""
    ...

@shared_task
def cleanup_old_alerts():
    """Limpia alertas antiguas"""
    ...
```

**Fortalezas**:
- ‚úÖ Tasks bien separados por responsabilidad
- ‚úÖ Usan `@shared_task` (correcto)
- ‚úÖ Tasks con `select_related` para optimizar queries

---

### üü° **MEJORA: Faltan periodic tasks configurados**

```python
# ‚ö†Ô∏è FALTA: Configuraci√≥n de Celery Beat para ejecutar tasks peri√≥dicos

# ‚ùå No hay celery.py en config/
# ‚ùå No hay schedule configurado
```

**Soluci√≥n**:
```python
# ‚úÖ CREAR: config/celery.py

import os
from celery import Celery
from celery.schedules import crontab

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

app = Celery('soptraloc')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

# ‚úÖ Configurar periodic tasks
app.conf.beat_schedule = {
    'check-unassigned-containers': {
        'task': 'apps.containers.tasks.check_containers_requiring_assignment',
        'schedule': crontab(minute='*/15'),  # ‚Üê Cada 15 minutos
    },
    'check-late-assignments': {
        'task': 'apps.containers.tasks.check_late_assignments',
        'schedule': crontab(minute='*/30'),  # ‚Üê Cada 30 minutos
    },
    'check-critical-assignments': {
        'task': 'apps.containers.tasks.check_critical_assignments',
        'schedule': crontab(hour='*/1'),     # ‚Üê Cada hora
    },
    'cleanup-old-alerts': {
        'task': 'apps.containers.tasks.cleanup_old_alerts',
        'schedule': crontab(hour=3, minute=0),  # ‚Üê Diario a las 3 AM
    },
    'calculate-daily-metrics': {
        'task': 'apps.containers.tasks.calculate_daily_metrics',
        'schedule': crontab(hour=0, minute=30),  # ‚Üê Diario a las 00:30
    },
    'invalidate-dashboard-cache': {
        'task': 'apps.core.tasks.invalidate_dashboard_cache',
        'schedule': crontab(minute='*/5'),  # ‚Üê Cada 5 minutos
    },
}

app.conf.timezone = 'America/Santiago'

# ‚úÖ AGREGAR: config/__init__.py
from .celery import app as celery_app

__all__ = ('celery_app',)

# ‚úÖ Ejecutar:
# celery -A config worker --loglevel=info
# celery -A config beat --loglevel=info  # ‚Üê Para periodic tasks
```

---

### üü° **MEJORA: Tasks sin retry ni error handling**

```python
# ‚ö†Ô∏è apps/containers/tasks.py
@shared_task
def check_containers_requiring_assignment():
    """‚ùå Sin retry ni error handling"""
    try:
        # C√≥digo del task
        ...
    except Exception as e:
        # ‚Üê Solo logging, no retry
        logger.error(f"Error: {e}")
```

**Soluci√≥n**:
```python
# ‚úÖ MEJORAR: Agregar retry y error handling

@shared_task(
    bind=True,
    max_retries=3,
    default_retry_delay=60  # 1 minuto
)
def check_containers_requiring_assignment(self):
    """‚úÖ Con retry autom√°tico"""
    try:
        containers = Container.objects.filter(
            status__in=related_status_values('PROGRAMADO'),
            scheduled_date__lte=timezone.localdate(),
            conductor_asignado__isnull=True
        ).select_related('client', 'owner_company')
        
        # Proceso del task...
        
    except Exception as exc:
        logger.error(f"Error en check_containers: {exc}")
        # Retry con exponential backoff
        raise self.retry(exc=exc, countdown=60 * (2 ** self.request.retries))

# ‚úÖ AGREGAR: Task de limpieza de cache

@shared_task
def invalidate_dashboard_cache():
    """Invalida cache del dashboard peri√≥dicamente"""
    from django.core.cache import cache
    
    cache.delete('dashboard:stats')
    cache.delete_pattern('container:list:*')  # ‚Üê Requiere django-redis
    logger.info("‚úÖ Cache del dashboard invalidado")

# ‚úÖ AGREGAR: Task de precarga de cache (warm-up)

@shared_task
def warmup_cache():
    """Pre-carga datos frecuentes en cache"""
    from apps.containers.services.stats_service import ContainerStatsService
    
    # Pre-cargar stats
    ContainerStatsService.get_status_counts(force_refresh=True)
    ContainerStatsService.get_driver_availability()
    
    logger.info("‚úÖ Cache precargado exitosamente")
```

---

## 5Ô∏è‚É£ AN√ÅLISIS DE DATABASE CONNECTION POOLING

### üü° **PROBLEMA: Sin connection pooling configurado**

```python
# ‚ö†Ô∏è config/settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': config('DB_NAME', default='soptraloc'),
        'USER': config('DB_USER', default='postgres'),
        'PASSWORD': config('DB_PASSWORD', default='password'),
        'HOST': config('DB_HOST', default='localhost'),
        'PORT': config('DB_PORT', default='5432'),
        # ‚ùå FALTA: Connection pooling
    }
}
```

**Problemas**:
- üü° Cada request crea nueva conexi√≥n DB (overhead)
- üü° Sin l√≠mite de conexiones (puede saturar PostgreSQL)

**Soluci√≥n**:
```python
# ‚úÖ IMPLEMENTAR: Connection pooling con django-db-geventpool

# requirements.txt
# django-db-geventpool==4.0.1  # ‚Üê Agregar

# config/settings_production.py
DATABASES = {
    'default': {
        'ENGINE': 'django_db_geventpool.backends.postgresql_psycopg2',  # ‚Üê Pooling
        'NAME': config('DB_NAME'),
        'USER': config('DB_USER'),
        'PASSWORD': config('DB_PASSWORD'),
        'HOST': config('DB_HOST'),
        'PORT': config('DB_PORT', default='5432'),
        'CONN_MAX_AGE': 60,  # ‚Üê Mantener conexi√≥n 60 segundos
        'OPTIONS': {
            'MAX_CONNS': 20,      # ‚Üê M√°ximo 20 conexiones en pool
            'REUSE_CONNS': 10,    # ‚Üê Reusar hasta 10 conexiones
        },
    }
}

# Alternativa con pgbouncer (m√°s robusto para producci√≥n):
# En Render.com, configurar PgBouncer:
# DATABASE_URL = "postgresql://user:pass@pgbouncer:6432/dbname"
```

---

## 6Ô∏è‚É£ AN√ÅLISIS DE COMPRESI√ìN Y ASSETS

### üü° **PROBLEMA: Sin compresi√≥n de respuestas**

```python
# ‚ö†Ô∏è config/settings.py
# WhiteNoise configurado, PERO sin GZip

MIDDLEWARE = [
    ...,
    'whitenoise.middleware.WhiteNoiseMiddleware',  # ‚Üê Sin compresi√≥n
    ...
]

STATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'
# ‚Üê Comprime archivos est√°ticos, PERO no respuestas HTTP
```

**Soluci√≥n**:
```python
# ‚úÖ AGREGAR: Compresi√≥n de respuestas HTTP

# requirements.txt
# django-compression-middleware==0.5.0  # ‚Üê Agregar

# config/settings.py
MIDDLEWARE = [
    'django.middleware.gzip.GZipMiddleware',  # ‚Üê AGREGAR como primero
    'django.middleware.security.SecurityMiddleware',
    'whitenoise.middleware.WhiteNoiseMiddleware',
    'corsheaders.middleware.CorsMiddleware',
    ...
]

# Configuraci√≥n adicional
GZIP_COMPRESS_LEVEL = 6  # Balance velocidad/compresi√≥n (1-9)
GZIP_MIN_LENGTH = 1024   # Solo comprimir > 1KB

# ‚úÖ Compresi√≥n de archivos est√°ticos (ya configurado)
STATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'

# ‚úÖ AGREGAR: Compresi√≥n de JSON responses en DRF
# apps/core/renderers.py
from rest_framework.renderers import JSONRenderer
import gzip

class CompressedJSONRenderer(JSONRenderer):
    """Renderer con compresi√≥n Gzip"""
    def render(self, data, accepted_media_type=None, renderer_context=None):
        response = super().render(data, accepted_media_type, renderer_context)
        
        # Si response > 1KB, comprimir
        if renderer_context and len(response) > 1024:
            request = renderer_context.get('request')
            if request and 'gzip' in request.META.get('HTTP_ACCEPT_ENCODING', ''):
                compressed = gzip.compress(response)
                renderer_context['response']['Content-Encoding'] = 'gzip'
                return compressed
        
        return response

# config/settings.py
REST_FRAMEWORK = {
    ...,
    'DEFAULT_RENDERER_CLASSES': [
        'apps.core.renderers.CompressedJSONRenderer',  # ‚Üê Usar renderer comprimido
    ],
}
```

---

## 7Ô∏è‚É£ AN√ÅLISIS DE PROFILING Y MONITORING

### üî¥ **PROBLEMA: Sin herramientas de profiling**

```python
# ‚ùå FALTA: Django Debug Toolbar (desarrollo)
# ‚ùå FALTA: django-silk (profiling en producci√≥n)
# ‚ùå FALTA: Sentry (error tracking)
# ‚ùå FALTA: New Relic / DataDog (APM)
```

**Soluci√≥n**:
```python
# ‚úÖ AGREGAR: Django Debug Toolbar (solo desarrollo)

# requirements.txt
# django-debug-toolbar==4.5.0  # ‚Üê Agregar

# config/settings.py
if DEBUG:
    INSTALLED_APPS += ['debug_toolbar']
    
    MIDDLEWARE = [
        'debug_toolbar.middleware.DebugToolbarMiddleware',  # ‚Üê Despu√©s de GZip
    ] + MIDDLEWARE
    
    INTERNAL_IPS = ['127.0.0.1', 'localhost']
    
    DEBUG_TOOLBAR_CONFIG = {
        'SHOW_TOOLBAR_CALLBACK': lambda request: DEBUG,
        'DISABLE_PANELS': [],
        'SHOW_TEMPLATE_CONTEXT': True,
    }

# config/urls.py
if settings.DEBUG:
    import debug_toolbar
    urlpatterns += [
        path('__debug__/', include(debug_toolbar.urls)),
    ]

# ‚úÖ AGREGAR: django-silk (profiling producci√≥n seguro)

# requirements.txt
# django-silk==5.2.0  # ‚Üê Agregar

# config/settings.py
INSTALLED_APPS += ['silk']

MIDDLEWARE = [
    'silk.middleware.SilkyMiddleware',  # ‚Üê Despu√©s de Debug Toolbar
] + MIDDLEWARE

SILKY_PYTHON_PROFILER = True
SILKY_AUTHENTICATION = True  # ‚Üê Solo usuarios autenticados
SILKY_AUTHORISATION = True
SILKY_MAX_REQUEST_BODY_SIZE = 10240  # 10KB
SILKY_MAX_RESPONSE_BODY_SIZE = 10240

# config/urls.py
urlpatterns += [
    path('silk/', include('silk.urls', namespace='silk')),
]

# ‚úÖ AGREGAR: Sentry (error tracking)

# requirements.txt
# sentry-sdk==2.18.0  # ‚Üê Agregar

# config/settings_production.py
import sentry_sdk
from sentry_sdk.integrations.django import DjangoIntegration
from sentry_sdk.integrations.celery import CeleryIntegration

sentry_sdk.init(
    dsn=config('SENTRY_DSN'),
    integrations=[
        DjangoIntegration(),
        CeleryIntegration(),
    ],
    traces_sample_rate=0.1,  # ‚Üê 10% de transacciones
    profiles_sample_rate=0.1,
    send_default_pii=False,  # ‚Üê No enviar PII
    environment='production',
    release=config('RELEASE_VERSION', default='dev'),
)
```

---

## 8Ô∏è‚É£ QUERY OPTIMIZATION EXAMPLES

### üî¥ **ANTI-PATTERN: Queries en loops**

```python
# ‚ùå MAL: N queries
containers = Container.objects.filter(status='PROGRAMADO')
for container in containers:
    driver = container.conductor_asignado  # ‚Üê 1 query por iteraci√≥n
    if driver:
        print(driver.nombre)
        print(driver.vehicle.plate)  # ‚Üê +1 query por iteraci√≥n
```

**Soluci√≥n**:
```python
# ‚úÖ BIEN: 1 query con select_related
containers = Container.objects.filter(status='PROGRAMADO').select_related(
    'conductor_asignado',
    'conductor_asignado__vehicle'  # ‚Üê Nested select_related
)
for container in containers:
    driver = container.conductor_asignado  # ‚Üê 0 queries
    if driver:
        print(driver.nombre)
        print(driver.vehicle.plate)  # ‚Üê 0 queries
```

---

### üî¥ **ANTI-PATTERN: Cargar objetos completos para counts**

```python
# ‚ùå MAL: Carga todos los objetos en memoria
containers = Container.objects.filter(status='PROGRAMADO')
total = len(containers)  # ‚Üê Carga TODOS los objetos
```

**Soluci√≥n**:
```python
# ‚úÖ BIEN: Count en DB
total = Container.objects.filter(status='PROGRAMADO').count()  # ‚Üê 1 query simple

# ‚úÖ BIEN: Exists para checks booleanos
has_programados = Container.objects.filter(status='PROGRAMADO').exists()  # ‚Üê M√°s r√°pido que count
```

---

### üî¥ **ANTI-PATTERN: Solo cargar IDs para otro query**

```python
# ‚ùå MAL: 2 queries
container_ids = Container.objects.filter(status='PROGRAMADO').values_list('id', flat=True)
containers = Container.objects.filter(id__in=container_ids).select_related('client')
```

**Soluci√≥n**:
```python
# ‚úÖ BIEN: 1 query
containers = Container.objects.filter(status='PROGRAMADO').select_related('client')
```

---

## üéØ PUNTUACI√ìN POR CATEGOR√çA

| Categor√≠a                          | Puntuaci√≥n | Comentario                                      |
|------------------------------------|------------|-------------------------------------------------|
| **Queries N+1**                    | 7/10       | üü¢ select_related bien usado, falta prefetch    |
| **Caching**                        | 3/10       | üî¥ Redis sin usar, sin cache de stats           |
| **Indexing**                       | 7/10       | üü¢ √çndices b√°sicos, faltan compuestos           |
| **Celery/Async**                   | 8/10       | üü¢ Bien configurado, falta Beat schedule        |
| **Database Pooling**               | 5/10       | üü° Sin pooling expl√≠cito                        |
| **Compresi√≥n**                     | 4/10       | üü° WhiteNoise OK, sin GZip responses            |
| **Profiling**                      | 2/10       | üî¥ Sin herramientas de profiling                |
| **Query Optimization**             | 7/10       | üü¢ Usa ORM correctamente, pocos antipatterns    |
| **API Response Time**              | 6/10       | üü° Sin cache, podr√≠a ser m√°s r√°pido             |
| **Static Files**                   | 8/10       | üü¢ WhiteNoise configurado correctamente         |

**PROMEDIO**: **5.7/10** üü° **NECESITA MEJORAS**

---

## üìã RECOMENDACIONES PRIORIZADAS

### üî¥ **CR√çTICO (Hacer HOY - Performance bloquea escalabilidad)**

1. **Implementar cache con Redis INMEDIATAMENTE**
   ```python
   # config/settings.py
   CACHES = {
       'default': {
           'BACKEND': 'django.core.cache.backends.redis.RedisCache',
           'LOCATION': config('REDIS_URL', default='redis://localhost:6379/1'),
       }
   }
   ```
   **Impacto**: Dashboard 10x m√°s r√°pido, reduce carga DB

2. **Cachear stats del dashboard**
   ```python
   @cache_page(60 * 2)  # 2 minutos
   def dashboard_view(request):
       ...
   ```
   **Impacto**: Reduce queries de 20+ a 3-5 por request

3. **Agregar √≠ndices faltantes**
   ```python
   models.Index(fields=['owner_company'], name='idx_owner'),
   models.Index(fields=['is_active', 'status'], name='idx_active_status'),
   ```
   **Impacto**: Queries 5-10x m√°s r√°pidas

---

### üî¥ **CR√çTICO (Hacer ESTA SEMANA)**

4. **Configurar Celery Beat para periodic tasks**
   ```python
   # config/celery.py con beat_schedule
   ```
   **Impacto**: Automatiza limpieza, m√©tricas, alertas

5. **Implementar prefetch_related en detail views**
   ```python
   qs.prefetch_related('movimientos', 'documentos')
   ```
   **Impacto**: Elimina N+1 en relaciones inversas

6. **Agregar connection pooling**
   ```python
   'ENGINE': 'django_db_geventpool.backends.postgresql_psycopg2',
   ```
   **Impacto**: Reduce latencia DB en 30-50ms por request

---

### üü° **IMPORTANTE (Pr√≥ximas 2 semanas)**

7. **Implementar compresi√≥n GZip**
8. **Agregar Django Debug Toolbar (dev)**
9. **Configurar Sentry para error tracking**
10. **Optimizar queries en resueltos_view (4 counts ‚Üí 1)**
11. **Cache de API responses con drf-extensions**
12. **Warm-up cache task peri√≥dico**

---

### üü¢ **MEJORAS (Backlog)**

13. Implementar CDN para assets est√°ticos
14. Agregar lazy loading en templates
15. Implementar pagination cursor-based (m√°s eficiente)
16. Configurar read-replica para queries pesados
17. Agregar monitoring con Prometheus + Grafana

---

## üéØ PR√ìXIMOS PASOS (FASE 8)

Con el an√°lisis de performance completo, ahora proceder√© a:

1. ‚úÖ **FASE 1 COMPLETADA**: Arquitectura y dependencias (5.3/10)
2. ‚úÖ **FASE 2 COMPLETADA**: Modelos y base de datos (5.4/10)
3. ‚úÖ **FASE 3 COMPLETADA**: L√≥gica de negocio y servicios (5.9/10)
4. ‚úÖ **FASE 4 COMPLETADA**: Views y controladores (4.5/10)
5. ‚úÖ **FASE 5 COMPLETADA**: APIs y Serializers (5.4/10)
6. ‚úÖ **FASE 6 COMPLETADA**: Seguridad profunda (6.3/10)
7. ‚úÖ **FASE 7 COMPLETADA**: Performance y optimizaci√≥n (5.7/10)
8. ‚è≥ **FASE 8**: Tests y cobertura
9. ‚è≥ **FASE 9**: Documentaci√≥n
10. ‚è≥ **FASE 10**: Deployment e integraci√≥n

---

**FIN DE FASE 7 - PERFORMANCE Y OPTIMIZACI√ìN**  
**Pr√≥ximo paso**: An√°lisis exhaustivo de tests (unitarios, integraci√≥n, coverage, tests de seguridad, tests de ML)
